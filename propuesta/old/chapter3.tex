\chapter{Sistemas de Control de Sistemas Distribuidos Inspirados en la Naturaleza} \label{bioinspired}


\section{Introducción}
Las colonias de hormigas, abejas, termita y avispas son ejemplos increibles de trabajo colectivo. Estos insectos \textit{sociales} han tenido un gran éxito en el proceso de adapadaptaciónos lugares más variados y difíciles de la tierra 

Durante años se han realizado estudios sobre las hormigas, abejas y avispas y su comportamiento ha sido tomado como fuente de inspiraci\'on, debido a la impresionante eficiencia de sus sociedades {\cite{BBCM01}}. Considere una
colonia de termitas, las cuales, individualmente poseen una inteligencia limitada y trabajan sin supervisi\'on, colectivamente construyen estructuras complejas, capaces de mantener la temperatura y los niveles de concentraci\'on
de di\'oxido de carbono y ox\'{\i}geno en valores adecuados para el crecimiento de sus larvas. Estas estructuras sociales son auto-organizadas, coordinadas por interacciones individuales de miembros de la colonia. En conjunto estos individuos pueden resolver problemas complejos, como por ejemplo, encontrar el camino m\'as corto entre la fuente de comida y la colonia. El funcionamiento colectivo que emerge de un grupo de insectos sociales recibe el nombre de {\textit{inteligencia de enjambre}} ({\textit{swarm intelligence}}). El \'exito de las sociedades de insectos se debe a tres caracter\'{\i}sticas:

\begin{enumerate}
  \item Flexibilidad: Adaptabilidad a cambios en el ambiente.
  \item Robustez: Si uno o m\'as individuos fallan (mueren) el grupo contin\'ua realizando su funci\'on.
  \item Auto-organizaci\'on: Las actividades no se controlan de manera   centralizada, ni se realiza una supervisi\'on local. El funcionamiento del grupo emerge de las interacciones colectivas de todos los individuos.
\end{enumerate}

Para entender el poder de la auto-organizaci\'on, considere como ciertas especies de hormigas son capaces de encontrar el camino m\'as corto a una fuente de comida solo con colocar y seguir caminos qu\'{\i}micos. Individualmente, las hormigas segregan feromonas, las cuales atraen a otras hormigas; en un ejemplo simple dos hormigas abandonan la colonia al mismo tiempo y toman diferentes caminos hacia la fuente del alimento; la hormiga que 
elige el camino m\'as corto regresar\'a primero y su camino estar\'a marcado por el doble de concentraci\'on de feromonas (las de ida y las de vuelta), esto hace m\'as atractivo este camino para las otras hormigas las cuales al
recorrerlo contin\'uan aumentando la concentraci\'on de feromonas.

Un modelo \'util que puede ser tomado del comportamiento de las sociedades de insectos es la divisi\'on de tareas: en las colonias los individuos se especializan en ciertas tareas, esta distribuci\'on es muy flexible y permite el cambio de funciones, por ejemplo, cuando el alimento escasea las abejas enfermeras (encargadas de cuidar las larvas) ayudan a las recolectoras.

\subsection{Conceptos Básicos}
Martinoli en \cite{AM99} realiza unas definiciones básicas para este estudio y son presentadas a continuación:

\subsubsection{Autonomía}
Los \textit{robots móbiles} trabajan en entornos imprevisibles y dinámicos. Como consecuencia los robots deben ser provistos con un buen número de sensores y con un poder de procesamiento adecuado. Los robots pueden dividirse en dos categorías: autonomos y guiados por humanos. En \cite{AM99} los robots muestran su auto-suficiencia en los siguientes niveles:
\begin{enumerate}
 \item Energético: EL robot no tiene un cable de alimentación.
 \item Computacional: Todos los sensores, actuadores y recursos computacionales están en el robot.
 \item Decisión: Los contrladores exhiben un comportamiento reactivo, algunas veces extendido con capacidades de memoria.
\end{enumerate}

\subsubsection{Localidad y Globalidad}
El termino \textit{local} es utilizado para indicar proximidad física. \textit{La comunicación local} o \textit{sensado} se refiere a una percepción idividual del mundo, basado en un marco de referencia individual.

El término \textit{global} involucra la totalidad del grupo independientemente de la posición de sus miembros dentro del entorno, lo cual requiere un marco de referencia para los miembros del grupo. Por lo tanto la \textit{Comunicación Global} implica un rango de comunicación sin límites.

\subsubsection{Inteligencia}
Un idividuo se considera \textit{inteligente} si \cite{BETG94} es capaz de actuar en su entorno de tal forma que la condición de \textit{viabilidad} siempre se satisface. En otras palabras, un individuo inteligente puede mantener su \textit{identidad} durante toda su vida, no solo en cuanto a su mera existencia sino a sus funciones vitales y objetivos. Para un robot móbil autónomo esto significa el cumplimiento de su tarea sin quedar atascado en puntos muertos mientras evita obstáculos.

Esta definición contrasta con la definición de inteligencia en AI, en la que el paradigma adoptado normalmente se basa en la condición \textit{a priori}: tadas las acciones posibles en un estado de percepción dado son conocidas de antemano y el agente debe escoger para poder ser considerado \textit{Inteligente}.

Una de las posibles formas de inteligencia colectiva (la viabilidad del grupo es necesaria para lograr la del individuo) es la inteligencia de enjambre (\textit swarm intelligence)\footnote{Fukuda y Ueyama \cite{FTUT94} proponen la siguiente definición: La inteligencia de Grupo puede dividirse en Inteligencia Colectiva y en Inteligencia de enjambre. La primera emerge de la interacción entre individuos racionales, inteligentes, con capacidad de negociación, mientras la inteligencia de enjambre emerge de individuos no inteligentes}. Bonabeau, Dorigo, and Theraulaz expanden el concepto de inteligencia de enjambre ``para incluir cualquier intento de diseñar algoritmos o dispositivos que resuelven problemas distribuidos inspirado por el comportamiento colectivo de colonias de insectos sociales y otras sociedades de animales''.

\subsubsection{Auto-organización}
Según \cite{BETG+97}, la auto-organizacuión en insectos sociales se basa en los siguientes mecanismos:
\begin{itemize}
 \item Realimentación Positiva, e.g. reclutamiento de otros individuos o reforzamiento de un determinado comportamiento a nivel individual.
 \item Realimentación Negativa en forma de saturación extinción de recursos o competencia.
 \item Amplificación de fluctuaciones tales como caminatas aleatorias, errores o cambios de contexto aleatorios.
 \item Interacciones múltiples: se requiere una densidad mínima de individuos mutuamente tolerantes. (los individuos pueden ser capaces de explotar los resultados de sus propias actividades, asi como las de sus compañeros).
\end{itemize}

Según \cite{BETG+97}, las características de los sistemas auto-organizados son:
\begin{itemize}
 \item Creación de patrones espacio-temporales desde un medio inicialmente homogéneo. 
 \item Estabilidad múltiple (coexistencia de varios estados estables).
 \item Existencia de bifurcaciones cuando se varían algunos parámetros.
 \item 
\end{itemize}

Es importante notar que los sistemas auto-organizados no son necesariamente adapatativos a nivel individual o cooperativos Sin embargo, la naturaleza favorece a las formas de auto-organización que observamos en los insectos sociales porque ellos son cooperativos y/o adaptativos \cite{BETG+97}.

\subsubsection{Comportamiento Emergente}
Podemos hablar de \textit{comportamiento emergente individual} si el comportamiento resultante del robot no fué programado de forma explícita en cualquiera de sus bloques funcionales y emerge de interacciones entre ellos (bloque-bloque). De forma similar podemos hablar de \textit{Comportamiento Emergente de Grupo} solo si no existe 
rastro del comportamiento obtenido (o deseado) en el controlador individual y este comportamiento emerge de forma auto-organizada y con interacciones agente-entorno \cite{MDBU93}.


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%











%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{La aproximación ``Funcionamiento Básico''} 

\cite{MJM94} Propone un nivel de descripción, instanciado en el llamado ``comportamiento básico'', bloques constructores para síntesis y análisis de funcionamiento complejo de grupo en un sistema multi-agente. La Biología proporciona evidencia de soporte de unidades de funcionamiento básico en una variedad de niveles. Controlar una pierna de una rana, o un brazo humano, es una tarea compleja, especialmente si se realiza a bajo nivel. Con el fin de reducir la complejidad, la naturaleza impone una abstracción. Musaa - Ivaldi \& Giszter \cite{MFA92} muestran que un grupo relativamente pequeño de campos vectoriales básicos, encontrados en la espina de la rana, genera el repertorio completo del comportamiento motriz, aplicando combinaciones apropiadas de los vectores básicos. Tomando esto como idea, se definen funcionamientos como leyes de control que encapsulan grupos de restricciones, de tal forma que se logran metas particulares. Los funcionamientos básicos se definen como un grupo mínimo de tales comportamientos, con propiedades apropiadas, que toman ventaja de la dinámica de el sistema dado, para cumplir de forma efectiva con su repertorio de tareas.

Los comportamientos básicos son una herramienta que pretenden describir, especificar y predecir el funcionamiento del grupo. Si se seleccionan de forma adecuada estos pueden generar comportamientos grupales repetibles y predecibles. 

\subsection{Selección y evaluación de comportamientos básicos}

La idea de los comportamientos básicos es general: Ellos pretenden ser primitivas para estructurar, sintetizar y analizar el funcionamiento del sistema, asi como, bloques constructores para control, planeamiento y aprendizaje. Están relacionados con los atractores dinámicos, estados de equilibrio y otros términos utilizados para describir comportamientos estables, repetibles y primitivos de cualquier sistema.

Este trabajo se centra en los comportamientos básicos para generar interacciones de grupo inteligentes en sistemas multi-agente. Se basa en la creencia de que el funcionamiento global de estos sistemas es el resultado de las interacciones locales, las cuales están gobernadas por reglas simples. Los comportamientos básicos presentan un mecanismo para estructurar el espacio de posibles reglas locales en un pequeño grupo base.

\subsubsection{Criterio de Selección}
Para un dominio dado, puede seleccionarse un pequeño grupo de comportamientos base o básicos, a partir del cual se pueden generar comportamientos de grupo complejos y deseables. Este grupo básico debe cumplir con los siguientes criterios:

\textbf{Necesidad:} Un funcionamiento dentro de un grupo de comportamientos básico es necesario  si alcanza el objetivo requerido para el cumplimiento de la tarea de un agente, y además, este objetivo no puede cumplirse con cualquiera de los otros comportamientos o sus combinaciones. Es decir, un comportamiento básico no puede ser implementado en términos de otros comportamientos y no puede ser reducido a ellos.

\textbf{Suficiencia:} Un grupo de comportamientos básico es suficiente para cumplir un grupo de tareas en un dominio dado si no son necesarios otros comportamientos. El grupo de comportamientos básicos puede, bajo los operadores de combinación, generar todos los comportamientos grupales de alto nivel.

Si estos comportamientos son generados a mano, ellos podrían tener las siguientes propiedades:

\begin{enumerate}
 \item Simplicidad: El comportamiento puede ser implementado lo más simple posible.
 \item Localidad: Dentro de un marco de trabajo, el comportamiento puede ser generado por reglas locales, utilizando información local de sensores.
 \item Correctness: Dentro del modelo donde es probado, el comportamiento puede mantener el objetivo para el cual a sido diseñado dentro de un grupo de condiciones dadas en tiempo de diseño.
 \item Estabilidad: El comportamiento no es sensible a perturbaciones en las condiciones externas para las cuales ha sido diseñado.
 \item Repetibilidad: El comportamiento se puede realizar de acuerdo a las especificaciones en cada intento bajo condiciones y márgenes de error razonables. 
 \item Robustez: El desempeño del comportamiento no se degradada significativamente en presencia de errores y ruido de limites específicos.
 \item Escalabilidad: El comportamiento puede escalarse con aumento y disminución del tamaño del grupo.
\end{enumerate}


Es difícil imaginar una forma de medir la selección del grupo básico óptimo, ya que este depende de las tareas a las que será aplicado. Este trabajo no pretende determinar criterios de optimización, ni proporciona preuebas teóricas del correcto funcionamiento de los algorítmos de los comportamientos presentados.


\subsubsection{Comportamientos Básicos Para Movimiento en un Plano}

El trabajo experimental se centró en la interacción entre agentes móbiles en un espacio bi-dimensional. Este dominio tiene la complejidad deseada ya que el número de posibles comportamientos colectivos no está limitado. Afortunadamente, el espacio de posibles patrones espaciales y temporales puede ser clasificado en clases, y de esta forma pude ser visto de forma efectiva a un bajo nivel de resolución. La clasificación se basa en criterios específicos de dominio y tarea, los cuales permiten seleccionar las clases de comportamiento relevantes para centrarse en ellas. Los comportamientos básicos propuestos imponen dichas clases; ellos definen grupos de comportamientos sin especificar reglas particulares para implementarlas. El comportamiento de grupo en el dominio espacial puede verse como patrones espacio-temporales de la actividad de los agentes. Ciertas organizaciones de agentes espacialmente fijas son relevantes, asi como ciertos patrones espacio-temporales. Las organizaciones de agentes espacialmente fijas corresponden a logros de metas, mientras los patrones espacio-temporales corresponden al mantenimiento de las mismas.

\begin{table}
\centering
\begin{tabular}{|l p{10cm}|}
\hline
\textbf{Safe Wandering} & La habilidad de un grupo de agentes para moverse alrededor, mientras evitan
colisiones entre ellos y otros obstáculos. La naturaleza homogénoea de los agentes puede utilizarse para evitar colisiones entre agentes. Esto es, se pueden divisar dos estrategias diferentes; una para evitar colisiones entre agentes del mismo tipo, y otra para evitar colisiones con todo lo demás. \\

\textbf{Following} & La habilidad de dos o más agentes para moverse mientras se mantiene uno detrás del otro.\\

\textbf{Dispersion} & La habilidad de un grupo de agentes para dispersarse sobre un área con el fín de establecer y mantener una distancia mínima predeterminada.\\

\textbf{Aggregation}& La habilidad de un grupo de agentes de reunirse con el fin de establecer y mantener una distancia máxima predeterminada.\\
\textbf{Homming} &  La habilidad para alcanzar una región o lugar específico.\\
\hline
\end{tabular}
\caption{Grupo de comportamientos básicos para el dominio epacial}\label{espacial_set}
\end{table}

En el proceso de selección de los comportamientos básicos, el diseñador intenta decidir que grupo de comportamientos puede ser suficiente para un gran repertorio de metas. Mientras las propiedades dinámicas del sistema proporcionan restricciones bottom-up, las metas proporcionan una estructura top-down. Ambas influencias guían el proceso de selección. La minimización de energía es una meta universal de los sistemas físicos alimentados. En el dominio del movimiento en un plano, esta meta se traduce en minimización del movimiento \textit{non-goal-motion}. Dicho movimiento es generado por un comportamiento pobre en diseño, o por interferencia entre agentes. Por lo tanto, al minimizar la interferencia se maximiza el comportamiento \textit{goal-driven} y se minimizan movimientos innecesarios.

Minimizar la interferencia se traslada directamente en el cumplimiento de la meta de eliminar colisiones de forma inmediata y en el mantenimiento de la tarea de moverse evitando colisiones. La eliminación de colisiones en grupo se puede lograr utilizando la dispersión, un comportamiento que reduce la interferencia localmente. Eso también es útil en tareas que requieren cobertura de espacio, como por ejemplo, las que involucran búsqueda y exploración.

En contraste a las metas que minimizan la interacción disminuyendo la proximidad física, algunas involucran el intercambio de recursos a través de la proximidad física. Por lo tanto, la agregación es la primitiva más útil. moverse en un grupo requiere alguna forma de coordinación de movimiento con el fín de minimizar interferencias. Ejemplos de este tipo de movimiento estructurado son Following y Flocking.

La Tabla \ref{espacial_set} muestra una lista de comportamientos que constituyen un grupo básico para un repertorio flexible de interacciones de grupo.

\subsection{Especificaciones del Comportamiento Básico}

Los comportamientos básicos en un espacio 2D se especifican en términos de posiciónes \textit{p}, distancias \textit{d}, y umbrales de distancias $\delta_{avoid}$, $\delta_{disperse}$ y $\delta_{aggregate}$.\\

$\mathcal{R}$ es el grupo de robots: $\mathcal{R} = \left\lbrace R_{i} \right\rbrace, 1 \le i \le n $\\

$p_{i} =  \begin{pmatrix} x_{i} \\ y_{i} \end{pmatrix}$    $p_{home} =  \begin{pmatrix} x_{home} \\ y_{home} \end{pmatrix}$\\

$d_{home,i}=\sqrt{(x_{home}-x_{i})^{2} + (y_{home}-y_{i})^{2}}$¸\\

$d_{i,j}=\sqrt{(x_{i}-x_{j})^{2} + (y_{i}-y_{j})^{2}}$¸\\

Utilizando esta notación las siguientes son las especificaciones para las metas de comportamiento básico:

\underbar{Safe Wandering:}

El objetivo de \textit{Safe-Wandering} es conservar el movimiento mientras se mantiene una distancia mínima entre agentes $\delta_{avoid}$:

$\frac{dp_{j}}{dt} \ne 0  \qquad y \qquad \forall{i} d_{i,j} >  \delta_{avoid}$ \\

\underbar{following:}

El objetivo de \textit{following} es alcanzar y mantener un ángulo mínimo $\theta$ entre la posición del lider \textit{i} relativa al seguidor \textit{j}: \bigskip

$i=$líder      $j=$seguidor \\ \bigskip
$0 \le \frac{dp_{j}}{dt} \centerdot (p_{i}-p_{j}) \qquad \le \qquad \parallel \frac{dp_{j}}{dt} \parallel \parallel (p_{i}-p_{j})  \parallel cos \theta $ \\ \bigskip
$\theta  = 0 \Rightarrow cos \theta = 0$ \\ \bigskip


\underbar{Dispersion:}
El objetivo de la \textit{Dispersion} es alcanzar y mantener una distancia máxima $\delta_{aggregate}$ entre los agentes.

$\forall{j} d_{i,j} >  \delta_{aggregate}$ \\

\underbar{Homming}
El objetivo de \textit{Homming} es disminuir la distancia entre el agente y una posición objetivo llamada ``home'':

$\forall{j} \frac{dp_{j}}{dt} \centerdot (p_{j}-p_{home}) <  0 $\\



\lstset{backgroundcolor=\color{white},frame=simple,emph={EMPTY},emphstyle=\color{white}, showstringspaces=false,numbers=left,stepnumber=2,numberstyle=\tiny,backgroundcolor=\color{code-color}}


%################################################################################################################
%#######################################################################     ALGORITMOS DE COMPORTAMIENTO BASICOS
%################################################################################################################

\subsection{Algoritmos de Comportamiento Básico}
Los algorítmos aquí presentados están dados en notación formal y en seudo-código. Todos son expresados formalmente como comandos de velocidad en la forma:

$command(v)$\\
Los operadores $\mathcal{N}$ y $\mathcal{C}$ se utilizan para calcular en la mayoría de los algorimos. $\mathcal{N}$ es el \textbf{operador vecindad}, el cual, dado un robot $\mathcal{R}$ y una distancia umbral $\delta$, retorna todos los robots dentro de la vecindad: \\

$\mathcal{N}(i,\delta)={\left\lbrace j \in i, ..n | d_{i,j}\right\rbrace  \le \delta}$

$\mathcal{C}$ es el \textbf{operador centroide}, el cual, dado un robot $i$ y una distancia umbral $\delta$, retorna el centroide local:

$\mathcal{C}(i,\delta)=\frac{\sum_{j\in \mathcal{N}(i,\delta)}p_{j}}{\left | \mathcal{N}(i,\delta) \right | }$

$\mathcal{C}_{g} = \frac{\sum_{j\in \mathcal{R}}p_{j}}{\left | n \right |}$

\subsubsection{Safe-Wandering}
Las estrategias para moverse mientras se evitan colisiones son talvez el tópico más estudiado en la robótica móbil. Encontrar una estrategia de propósito general de evasión de obstáculos para un agente situado en un mundo dinámico es una tarea difícil. En un entorno multi-agente el problema puede ser muy difícil de resolver.

El comportamiento de evasión utilizado es:

$command (v \displaystyle{cos(\theta + u) \choose sin(\theta + u)} ) $  \\

donde $\theta$ es la orientación de $\mathcal{R}$ y \textit{u} es el ángulo incremental desde el obstáculo. Se puede divisar la regla \textbf{Avoid-Other-Agents}:

\begin{lstlisting}[caption={Algoritmo Avoid-Other-Agents}, numbers=none]
Avoid-Other-Agents
If an agent is within d_avoid
  If the nearst agent is on the left
    turn right
    otherwise turn left
\end{lstlisting}

Este algoritmo toma ventaja de la homogeneidad del grupo. Ya que todos los agentes ejecutan la misma estrategia, el comportamiento puede confiar y tomar ventaja de la simetria espacial redundante. Si un agente falla al reconocer a otro con sus sensores especialiazados para esa tarea, puede detectarlo con los sensores de evasión, y tratarlo como un obstáculo genérico, utilizando el siguiente algoritmo:

\begin{lstlisting}[caption={Algoritmo Avoid-Everything-Else}, numbers=none]
Avoid-Everything-Else
If an obstacle is within d_avoid
  If an obstacle is on the right only, turn left.

  If an obstacle is on the left only, turn right.
  After 3 consecutive identical turns, backup and turn.

  If an obstacle is on both sides, stop and wait.
  If an obstacle persist on both sides, 
     turn randomly and back up.
\end{lstlisting}

Con el fín de aumentar la robustez y minimizar las oscilaciones, esta estrategia toma ventaja del inevitable ruido en los sensores y actuadores, lo cual es un comportamiento estocástico. Este componente estocástico garantiza que un agente evasor no se quedará en lazos infinitos y oscilaciones. Adicionalmente a la naturaleza implícita estocástica del comportamiento del robot. El algoritmo \textit{Avoid-Everything-Else} también utiliza una estrategia explicitamente probabilistica al utilizar movimientos aleatorios.

Se probaron experimentalmente variaciones de este algoritmo de evasión y se compararon con base en la cantidad de tiempo que el agente tarda evadiendo, relativo a la cantidad de tiempo que tarda moviendose libremente. Esta relación es una medida indirecta de la calidad de la estrategia de evasión, ya que mientras más tiempo gaste el agente evadiendo peor es la estrategia. El tiempo de evasión depende de la densidad de agentes, por lo que fué utilizada como una variable controlada en los experimentos. La relación utilizada para evaluar la evasión es una medida indirecta; una medición de cuando el robot esté ``estancado'' sería más útil, pero en estos experimentos los robots no contaban con senosores que les permitieran detectar este estado.

La estrategia para \textit{safe-wandering} es la combinación de dos estrategias de evasión con una regla por defecto para el movimiento con cambios ocasionales de dirección.

\begin{lstlisting}[caption={:}, numbers=none]
Safe--Wander:
  If an agent is within d_avoid
    If the nearest agent is on the left
      turn right
      otherwise turn left.
  If an obstacle is within d_avoid
    If an obstacle is on the right only, turn left.
    If an obstacle is on the left only, turn right.
    After 3 consecutive identical turns, backup and turn.
    
    If an obstacle is on both sides, stop and wait.
    If an obstacle persists on both sides,
      turn randomly and back up.
  Otherwise move forward by d_forward, turn randomly
\end{lstlisting}

\subsubsection{Following}

El comportamiento \textit{Following} se implementa con respecto al agente seguidor. Se implementa con una regla simple que dirige al seguidor a la posición del lider:

$command(\frac{v_{0}}{ \left \| p_{leader}-p_{follower} \right \|}(p_{leader}-p_{follower}))$

Este comportamiento puede ser implementado como como un complemento del algoritmo \textit{Avoid-Everything-Else}:
\begin{lstlisting}[caption={:}, numbers=none]
Follow:
  If an agent is within d_follow 
    If an agent is on the right only, turn right.

    If an agent is on the left only, turn left.
\end{lstlisting}

\subsubsection{Dispersion}
Un algorítmo de dispersión robusto se puede diseñar como una extensión del algoritmo \textit{safe-wandering}. Mientras la evasión en \textit{safe-wandering} reacciona a la presencia de un solo agente,  \textit{dispersion} utiliza la distribución local de todos los agentes cercanos (los que se encuentran al alcance de los sensores) para determinar en que dirección moverse.

\begin{lstlisting}[caption={:}, numbers=none]
Centroid-Disperse:
  If one or more agents are within d_disperse
    move away from Centroid_disperse.
\end{lstlisting}

El algoritmo anterior, calcula el centroide local para determinar la distribución de densidad local de los agentes cercanos y se aleja de la densidad más alta:

$command(\frac{-v_{0}}{\left \| \mathcal{C}(i,\delta_{disperse}-p_{i}) \right\|}(\mathcal{C}(i,\delta_{disperse}-p_{i})))$

Bajo condiciones de alta densidad, el sistema puede tomar mucho tiempo para alcanzar el estado de dispersión, ya que las interacciones locales se propagan y el movimiento de un individuo puede afectar el estado de los demás. Es decir, la \textit{dispersion} puede verse como un proceso en curso que mantiene una distancia deseada entre los agentes, mientras ellos realizan otras tareas.

El siguiente algoritmo fué más exitoso en términos de eficiencia y confiabilidad:

\begin{lstlisting}[caption={:}, numbers=none]
Neighbor-Disperse:
Find 2 nearest neighbors within d_disperse
Compute the angle between them,
Compute the negative of the bisector,
align in that direction and go forward.
\end{lstlisting}

\subsubsection{Aggregation}

La \textit{Aggregation} es el inverso de la dispersión:

$command(\frac{+v_{0}}{\left \| \mathcal{C}(i,\delta_{aggregate}-p_{i}) \right\|}(\mathcal{C}(i,\delta_{aggregate}-p_{i})))$
y puede ser implementado utilizando el operador centroide, como se muestra a continuación:

\begin{lstlisting}[caption={:}, numbers=none]
Aggregate:
  If nearest agent is outside d_aggregate
    turn toward the local Centroid_aggregate, go.
  Otherwise, stop.
\end{lstlisting}


\subsubsection{Homming}

La estrategia \textit{homming} más simple es:

$command( \frac{v_{0}}{\left \| p_{home} - p_{i} \right\|}(p_{home} - p_{i}) )$

y es implementada mediante el algoritmo:

\begin{lstlisting}[caption={:}, numbers=none]
Home:
If at home
  stop.
  otherwise turn toward home, go.
\end{lstlisting}

El \textit{homming} individual es efectivo cuando la densidad de agentes es baja. Si un número suficiente de de agentes son confinados en un determinado espacio, ellos interfieren entre sí. 


\section{Combinación de Comportamientos Básicos}

\subsection{Dos Tipos de Combinación}
Los comportamientos básicos están diseñados para ser un substrato para una variedad de comportamientos de grupo más complejos para un determinado dominio. Generar funcionamientos complejos requiere aplicar algún tipo de operadores de combinación cuyas propiedades sean bien conocidas y produzcan el funcionamiento compuesto deseado. Este es uno de los retos del control \textit{Basado en el Comportamiento}, esto es, coordinar la actividad de multiples comportamientos de entrada para producir el comportamiento de salida deseado.

Dependiendo de la complejidad del sistema, el arbitramento puede y normalmente debe ser realizado sobre múltiples puntos. Un nivel de arbitramento puede ser alcanzado al diseñar condiciones de comportamiento mutuamente excluyentes\cite{Mat92}. Creando una correspondencia uno a uno única entre condiciones y comportamientos se garantiza un grupo de pares condición-acción mutuamente excluyentes. En contraste, si la correspondencia es una a varios, de tal forma, que la condición puede originar más de un posible comportamiento, existe la posibilidad que dos o más comportamientos entren en conflicto.

Las condiciones de comportamiento mutuamente excluyentes son suficientemente poderosas para arbitrar sistemas que realizan solo un comportamiento a la vez. Sin embargo, en sistemas más complejos, comportamientos múltiples pueden contribuir a la salida. Consecuentemente, muchos sistemas prácticos utilizan condiciones de comportamiento mutuamente excluyentes dentro de una capa coherente o submódulos del sistema que manejan un set de tareas coherentes. Entre módulos y capas es necesario otro nivel de arbitraje, el cual puede implementar ya sea un tipo de suma de las entradas o un interruptor. La forma general de un sistema basado en el comportamiento involucra tal combinación de operadores a uno o más niveles.

Para obtener ventaja del poder combinatorio de los comportamientos básicos, la arquitectura propuesta utiliza dos tipos de operadores: Los comportamientos pueden ser combinados directamente, ejecutando multiples comportamientos a la vez y temporalmente, secuenciando los comportamientos uno a la vez. La combinación directa permite que multiples comportamientos activos de forma concurrente contribuyan a las salidas. Las combinaciones temporales aseguran una secuencia coherente de la salida. Los dos tipos de operadores de combinación, aplicados al grupo de comportamientos básicos, pueden generar un repertorio ilimitado de comportamientos colectivos, ya que las combinaciones temporales pueden extenderse en el tiempo de forma arbitraria. 

\subsubsection{Combinación Directa de Comportamientos}

Una combinación directa de comportamientos es alguna función de las salidas de un sub-grupo de los comportamientos básicos. En el dominio espacial, las salidas de todos comportamientos básicos están en la forma de vectores de dirección y velocidad, por lo que una suma ponderada apropiada de tales vectores produce directamente comportamientos de alto nivel coherentes. A manera de ejemplo, se muestra como, la combinación directa de algunos comportamientos básicos produce el comportamiento complejo  \textit{flocking}.

\textit{Flocking} se define como un movimiento colectivo que satisface las siguientes restricciones: todos los agentes dentro del área de los sensores de cada robot, deben estar dentro de una distancia dada a sus vecinos mientras se mueven. A diferencia del comportamiento \textit{aggregation}, \textit{flocking} no solo requiere que los agentes permanezcan juntos sino que se muevan juntos hacia un determinado punto, normalmente llamado \textit{home}. Formalmente:


$\forall(i,j) d_{i,j} < \delta_{flock} y \frac{dp\mathcal{C}_{g}}{dt}\centerdot(\mathcal{C}_{g}-p_{home})<0 $

\textit{Flocking} puede ser implementada combinando las salidas de \textit{safe-wandering}, \textit{aggregation}, \textit{dispersion} y \textit{homming} de forma tal que se cumplen las restricciones dadas. De forma intuitiva \textit{aggregation} mantiene a los robots cerca uno del otro, \textit{dispersion} hace que no estén demasiado cerca, y \textit{safe-wandering} previene individualmente a cada agente y al grupo como un todo, de colisionar con cualquier obstáculo no-agente, y \textit{homming} mueve el grupo hacia la meta. \textit{Flocking} puede ser reducido aún más a una combinación de \textit{safe-wandering}, \textit{aggregation} y \textit{homming} para un rango de valores de $\delta_{flock}$, tal que: $\delta_{flock} <\delta_{aggregate}$, ya que \textit{safe-wandering} también tiene un efecto de dispersión. \\

En la figura \ref{hfs} se muestran las combinaciones necesarias para obtener los comportamientos \textit{hearding} y \textit{surrounding}

\tikzstyle{format} = [draw, thin, fill=blue!20]
\tikzstyle{medium} = [circle, draw, thin, fill=green!20, minimum height=2.5em]

\begin{figure}[h]
\begin{center}
\begin{tikzpicture}
  \node[scale=0.6]{
    \begin{tikzpicture}[node distance=3cm, auto, thick]
        \path[-] node[format] (homing) {Homing};
        \path[-] node[format, right of=homing] (safe) {Safe-wandering};
        \path[-] node[format, right of=safe]   (disp) {Dispersion}
                node[medium, below left of=disp] (add1) {+}
                (homing) edge node {} (add1)
                (safe) edge node {} (add1)
                (disp) edge node {} (add1);
        \path[-] node[format, right of=disp]   (aggr) {Aggreagation}
                (aggr) edge node {} (add1);
        \path[-] node[format, right of=aggr]   (foll) {Following}
                node[medium, below left of=foll] (add2) {+}
                (aggr) edge node {} (add2)
                (foll) edge node {} (add2);
        \path (add1.south)  +(0,-1.2) node (floc) [format] {Flocking};
        \path (add2.south)  +(0,-1.2) node (surr) [format] {Surrounding};
        \path[-] node[medium, below left of=surr] (add3) {+};
        \path (add3.south)  +(0,-1.2) node (herd) [format] {Herding}
                (floc) edge node {} (add3)
                (surr) edge node {} (add3)
                (add2) edge node {} (surr)
                (add1) edge node {} (floc)
                (add3) edge node {} (herd);
    \end{tikzpicture}
  };
\end{tikzpicture}  
\caption{Ejemplo de combinación de comportamientos básicos} \label{hfs} 
 
\end{center}
\end{figure}

\subsubsection{Combinaciones Temporales de Comportamientos}

Los comportamientos básicos y sus combinaciones directas permiten alcanzar y mantener ciertas metas. Por ejemplo, \textit{dispersion} hace que todos los agentes se encuentren a una distancia mínima mientras que \textit{following} mantiene una fila de agentes en movimiento, los cuales se encuentran a una distancia dada de sus vecinos. Para poder realizar tareas de más alto nivel definidas por múltiples objetivos secuenciales, es necesario combinar temporalmente de forma apropiada los comportamientos básicos (ver figura \ref{temp}). Para que esto sea posible, es necesario confiar en la habilidad de los agentes para percibir el estado que origina el cambio de comportamiento. Si se cuenta con esta habilidad, es posible diseñar maquinas de estados finitos que generen una gran variedad de comportamientos multi-objetivo. Este método es ilustrado en la implementación de \textit{foraging} (figura \ref{temp}).


\tikzstyle{block} = [draw, fill=blue!20, rectangle, minimum height=3em, minimum width=6em]
\tikzstyle{sum}   = [draw, fill=blue!20, circle, node distance=3cm]
\tikzstyle{add}   = [circle, draw, thin, fill=green!20, minimum height=2.5em]
\tikzstyle{pinstyle} = [pin edge={to-,thin,black}]

\begin{figure}[h]
\begin{center}

\begin{tikzpicture}
  \node[scale=0.6]{
    \begin{tikzpicture}[auto, node distance=2cm]
        \node [block] (safe) {$safe-wandering$};
        \node [sum,   right of=safe] (sum1) {};
        \draw [to-] (sum1) -> node {} (safe);

        \node [block, below of=safe] (disp) {$dispersion$};
        \node [sum,   right of=disp] (sum2) {};
        \draw [to-] (sum2) -- node {} (disp);

        \node [block, below of=disp] (homi) {$homing$};
        \node [sum,   right of=homi] (sum3) {};
        \draw [to-] (sum3) -- node {} (homi);

        \node [block, below of=homi] (foll) {$following$};
        \node [sum,   right of=foll] (sum4) {};  
        \draw [to-] (sum4) -- node {} (foll);

        \node [add, below right of=sum1, node distance=4cm, pin={[pinstyle]below:Condiciones de sensores}, pin={[pin edge={-to,thin,black}]right:\textbf{foraging}}] (add1) {X};
        \draw [to-] (sum1) -- node {} (add1);
    \end{tikzpicture}
  };
\end{tikzpicture}
  

\caption{Implementación de  \textit{foraging} utilizandfo una combinación temporal de \textit{safe
wandering}, \textit{dispersion}, \textit{homing}, y \textit{following}} \label{temp} 
 
\end{center}
\end{figure}


En \textit{foraging}, el objetivo de alto nivel del grupo es recolectar objetos del entorno y llevarlos a un determinado lugar. Además de contar con los comportamientos básicos, los agentes son capaces de buscar objetos, recogerlos y llevarlos. \textit{Foraging} se inicia con la \textit{dispersion}, después \textit{safe-wandering}. Cuando se encuentra un objeto se activa \textit{homing}; encontrar un agente con una tarea inmediata diferente, genera \textit{safe-wandering} apartándose del objeto. Mientras que encuentrar otro agente con la misma tarea inmediata activa\textit{flocking}. Cuando se llega al lugar denominado \textit{home} y se deposita el objeto, se activa \textit{dispersion} si se encuentran varios agentes en este sitio, o  \textit{safe-wandering} si el robot se encuentra solo.

\tikzstyle{block} = [draw, fill=blue!20, rectangle, minimum height=3em, minimum width=6em]
\tikzstyle{sum}   = [draw, fill=blue!20, circle, node distance=3cm]
\tikzstyle{add}   = [circle, draw, thin, fill=green!20, minimum height=2.5em]
\tikzstyle{pinstyle} = [pin edge={to-,thin,black}]

\begin{figure}[h]
 
\begin{center}
\begin{tikzpicture}
  \node[scale=0.6]{
    \begin{tikzpicture}[auto, node distance=2cm]
        \node [block] (safe) {$safe-wandering$};
        \node [sum,   right of=safe] (sum1) {};
        \draw [to-] (sum1) -> node {} (safe);

        \node [block, below of=safe] (disp) {$dispersion$};
        \node [sum,   right of=disp] (sum2) {};
        \draw [to-] (sum2) -- node {} (disp);

        \node [block, below of=disp] (homi) {$homing$};
        \node [sum,   right of=homi] (sum3) {};
        \draw [to-] (sum3) -- node {} (homi);

        \node [block, below of=homi] (foll) {$following$};
        \node [sum,   right of=foll] (sum4) {};  
        \draw [to-] (sum4) -- node {} (foll);

        \node [add, below right of=sum1, node distance=4cm, pin={[pinstyle]below:Condiciones de sensores}, pin={[pin edge={-to,thin,black}]right:\textbf{foraging}}] (add1) {X};
        \draw [to-] (sum1) -- node {} (add1);
    \end{tikzpicture}
  };
\end{tikzpicture}
\caption{Implementación de  \textit{foraging} utilizandfo una combinación temporal de \textit{safe
wandering}, \textit{dispersion}, \textit{homing}, y \textit{following}} \label{temp} 
 
\end{center}
\end{figure}

La combinación es una tarea simple ya que, los conflictos entre dos o más agentes, (cada uno de ellos ejecutando un comportamiento diferente) son resueltos uniformemente gracias a la homegeneidad de los agentes. Ya que todos los agentes comparten la misma estructura objetivo, ellos responderán de forma consistente a las condiciones del entorno. Por ejemplo, si un grupo de agentes se dirigen hacia \textit{home} y encuentra varios agentes dispersos, la diferencia en los estados externos puede inducir a los agentes del grupo del mismo tipo o a los agentes dispersos de cualquier tipo, es decir, dividiendo o especializando al grupo de nuevo.


%################################################################################################################
%####################################################################### MRS FORMALISM DEFINITIONS AND NOTATION
%################################################################################################################

\section{Formalismo en Sistemas Multi-Robot (MRS)\cite{CVJ05}}
\begin{figure}[h]
 
\begin{center}

\tikzstyle{sensor}=[draw, fill=blue!20, text width=15em, text centered, minimum height=1em]
\tikzstyle{naveqs} = [sensor, text width=6em, fill=blue!50, minimum height=8em, rounded corners]
\def\blockdist{7}
\begin{tikzpicture}
  \node[scale=0.6]{
    \begin{tikzpicture}
        \node (naveq) [naveqs] {Analysis};
        \path (naveq.0)+(-\blockdist,0) node (synt) [naveqs] {Syntesis};
        \path (naveq.south west)+(-1.6,-1.4) node (INS) {Automated Controller Syntesis};

        \draw [to-] (naveq.90) .. controls +(up:1cm) and +(up:1cm) .. node [above, sloped]  {Robot Controller} (synt.90) ;
        \draw [-to] (naveq.-90) .. controls +(up:-1cm) and +(up:-1cm) .. node [above, sloped]  {Task Performance} (synt.-90) ;
        % Draw a rounded box around naveq & synt
        \begin{pgfonlayer}{background}
            \path (synt.west |- naveq.north)+(-.6,1.6) node (a) {};
            \path (INS.south -| naveq.east)+(+0.6,-0.4) node (b) {};
            \path[fill=blue!20,rounded corners, draw=black!50, solid] (a) rectangle (b);
        \end{pgfonlayer}
        \path (naveq.north) +(2,2.5) node (formal) [sensor] {Formal Understanding of Coordinated RMS};
        \path (naveq.south) +(2,-3) node   (coord) [sensor] {Coordinated RMS};
        \path (synt.north)  +(-2,2.5) node (defini) [sensor, fill=red!50] {Formal Definitions World, Task, Robots};

        \draw [-to] (naveq.east)+(.6,0) .. controls +(right:1.5cm) and +(down:1cm) ..  (formal.-20) ;
        \draw [-to] (naveq.east)+(.6,0) .. controls +(right:1.5cm) and +(up:1cm) ..     (coord.20) ;
          \draw [to-] (synt.west)+(-.6,0) .. controls +(left:1.5cm) and +(down:1cm) ..   (defini.-160) ;
    \end{tikzpicture}
  };
\end{tikzpicture}
  \caption{Metodología de Diseño de controladores para un MRS.} \label{glob_meth}
\end{center}
\end{figure}

\subsection{Mundo}
El mundo, W, es el entorno en el cual se espera que el MRS realice una determinada tarea. Se asume que el mundo es Markoviano, poblado por un número finito de robots R, y el estado es un elemento del grupo finito de posibles estados S. El estado del mundo en un tiempo \textit{t} se denota como:
\\
$S^{t}=\Xi_{1} X \cdot \cdot \cdot \Xi_{m}$

donde cada $\Xi_{i} \in \mathcal{S}$ representa el dominio de una característica individual del mundo. Este grupo de características puede contener muchos elementos dependientes del dominio; incluyendo la posición física de los robots, valores de los estados internos de cada robot, la localización, o relaciones de proximidad de los artefactos físicos presentes en el mundo. El estado del mundo $S$ representa el dominio de todas las posibles combinaciones de valores sobre estas características individuales.

$\left\lbrace A_{r\in\mathcal{R}}\right\rbrace$ es un grupo de acciones que cada robot \textit{r} puede ejecutar. $A^{t}_{r}$ representa la acción que cada robot \textit{r} hace en un tiempo \textit{t}. $\left\lbrace X_{r\in\mathcal{R}}\right\rbrace$ es el conjunto de observaciones que cada robot puede hacer. $X^{t}_{r}$ representa la observación que un robot puede hacer en un tiempo \textit{t}. Una observación esta formada por información externa accesible al robot y formalmente representa un un subgrupo del estado del mundo. La función probabilística observación:

$O(s,x)=P_{r}(X^{t}_{r} = x |S^{t}=s)$ \\

da la probabilidad que en un tiempo $t$ la observación $x$ se realice en el estado $s$ \\

El mundo esta definido por una función de transición de estados probabilística:

$P(s,a,s')=P_{r}(S^{t+1}=s'|S^{t}=s,A^{t}_{r}=a)$ \\

la cual declara que la probabilidad del estado del mundo en el tiempo $t+1$ es $s'$ dado que el estado del mundo en el tiempo $t$ fué $s$ y un robot $r$ ejecutó una acción $a$ en el tiempo $t$.

\subsection{Task}

Una tarea $T$ se define como un grupo de estados del mundo y transiciones de estado del mundo representadas por un grafo acíclico directo (DAG). En el DAG para una tarea $T$, cada vértice en el grupo finito de vértices $V_{T}$ es un único estado del mundo. Para cada vértice $u \in V_{T}$, todos los vértices $v$, tales que $\left\lbrace u,v \right\rbrace \in E_{T}$, son llamados \textit{hijos} de $u$. Cada lado en el grupo finito de lados $E_{T}$ entre los vértices $E_{T}=\left\lbrace(u,v) |u,v \in V_{T}\right\rbrace$ representa una acción $a$ tal que $P(u,a,v)>0$

Existe exactamente un vértice en el grafo denotado como $u\_start_{T} \in V_{T}$ que corresponde al estado inicial del mundo. Un sub-grupo de vértices del grafo son marcados como vértices terminales y se denotan como $u\_term_{T} \subseteq V_{T}$. Por lo tanto, debe existir un camino a través del grafo para cada vertice en $V_{T}$ hacia al menos un vertice en $u\_term_{T}$ (ver Figura \ref{graph}).

Si a cualquier tiempo $t, s_{t} \in \subseteq u\_term_{T}$, tarea la termina. Se define una \textit{Ejecución correcta de tarea} cuando las acciones combinadas de los robots hacen que el estado del mundo vayan del nodo inicial al nodo terminal. Si las acciones de los robots hacen que el estado del mundo vaya de un estado $s_{i}$ a un estado $s_{j}$ en el cual no existe un lado en $E_{T}$ que conecte los vertices correspondientes del grafo, la tarea \textit{no se ejecuta correctamente} y la ejecución de la misma termina inmediatamente.

\tikzstyle{state}=[circle,fill=blue!20,thick, inner sep=0pt,minimum size=10mm]
\tikzstyle{ends} =[circle,fill=red!20, thick, inner sep=0pt,minimum size=10mm]

\begin{figure}[h]
\begin{center}
\begin{tikzpicture}
  \node[scale=0.6]{
    \begin{tikzpicture}[auto,node distance=3cm, semithick]
    \node (S0)  at ( 0,0)     [ends]  {S0};
    \node (S2)  at ( 0,-1.5)  [state] {S2};
    \node (S12) at (1.5,1.5)  [state] {S12};
    \node (S11) at (1,-4)     [state] {S11};
    \node (S7)  at (3,3)      [state] {S7};
    \node (S10) at (2,-1)     [state] {S10};
    \node (S4)  at (4,0)      [state] {S4};
    \node (S5)  at (4.5,1.5)  [ends]  {S5};
    \node (S13) at (7,0.5)    [state] {S13};
    \node (S8)  at (4.5,-1.5) [state] {S8};
    \node (S1)  at (7,-1.5)   [state] {S1};
    \node (S9)  at (3.5,-3.5) [state] {S9};
    \node (S3)  at (5,-4.5)   [ends]  {S3};

    \draw [-to,snake=snake] (S0)  -- (S2);
    \draw [-to,snake=snake] (S0)  -- (S10);
    \draw [-to,snake=snake] (S12) -- (S0);
    \draw [-to,snake=snake] (S12) -- (S4);
    \draw [-to,snake=snake] (S12) -- (S7);
    \draw [-to,snake=snake] (S10) -- (S8);
    \draw [-to,snake=snake] (S10) -- (S9);
    \draw [-to,snake=snake] (S10) -- (S12);
    \draw [-to,snake=snake] (S11) -- (S10);
    \draw [-to,snake=snake] (S11) -- (S9);
    \draw [-to,snake=snake] (S9)  -- (S8);
    \draw [-to,snake=snake] (S9)  -- (S1);
    \draw [-to,snake=snake] (S9)  -- (S3);
    \draw [-to,snake=snake] (S2)  -- (S11);
    \draw [-to,snake=snake] (S8)  -- (S4);
    \draw [-to,snake=snake] (S8)  -- (S1);
    \draw [-to,snake=snake] (S4)  -- (S5);
    \draw [-to,snake=snake] (S4)  -- (S13);
    \draw [-to,snake=snake] (S13) -- (S5);
    \draw [-to,snake=snake] (S7)  -- (S5);
    \end{tikzpicture}
  };
\end{tikzpicture}
\caption{Representación gráfica de la descripción de la tarea $T$} \label{graph}

 
\end{center}
\end{figure}

\subsection{Robot}

Cada Robot en el sistema se considera funcionalmente identico y todos los Robots ejecutan los mismos controladores.

\subsubsection{Estado Interno Persistente}
Cada robot puede mantener en memoria persistente una cantidad finita de estados, la cual, puede ser modificada por el robot y ser utilizada para tomar decisiones de control. Los Datos que se almacenan durante pocos ciclos de control (Estado de los sensores, estado de los motores, buffers de comunicaciones) no se consideran como parte del estado interno, ya que no son persistentes.

El valor del estado interno de un robot $r$, $m_{r}$ es un miembro del grupo finito: $M_{r}=\left\lbrace i_{0}, ... , i_{0}\right\rbrace$, donde $i_{0}$ es el estado interno inicial de todos los robots. Se requiere que el valor de cada estado interno sea único.

\subsection{Comunicación entre Robots}
Cada robot puede comunicarse con los demás robots en el MRS utilizando una comunicación tipo \textit{broadcast}, la cual es recibida por todos los robots y se desconoce el orígen de la señal.

El grupo de todos los posibles mensajes de comunicación que un robot $r$ puede enviar y recibir es denotado por el conjunto $C_{r}=\left\lbrace c_{0}, ..., c_{q} \right\rbrace$; es necesario que cada mensaje sea único y distinguible. El mensaje de comunicación que un determinado robot $r$ se encuentre enviando se denota como $Cs_{r}$. El conjunto de mensajes que un robot $r$ esta recibiendo se denota como $Cr_{r}$.

\subsection{Controlador}

El comportamiento del robot en el mundo se define con 3 funciones, las cuales, en conjunto reciben el nombre de $controlador$ del robot; formado por una función de acción, una función de transición de estado interno y una función de comunicación.

La \textit{funcion de acción}

$Act(x,m,c,a)= Pr(A_{r}^{t}=a | X_{r}^{t}=x, M_{r}^{t}=m, Cr_{r}^{t}=c)$

da la probabilidad de que un robot $r$ ejecute una acción $a$ dado que recibe la observación $x$, tiene un valor de estado interno $m$, y recibe el mensaje de comunicación $Cr$.

Cuando se ejecutan las acciones de la función de acción, se puede cambiar el estado del mundo. Cada robot tiene un set adicional de acciones, llamadas acciones de $competencia$, que se ejecutan cuando no se ejecutan las acciones de la función de acción. Las acciones de competencia no cambian el estado del mundo cuando se ejecutan (por lo tanto no son importantes al momento de considerar la correcta o incorrecta ejecución de una tarea) y se utilizan principalmente en acciones como navegación local y evasión de obstáculos.

La \textit{función transición de estado interno}

$IState(x,m,c,m')= Pr(M_{r}^{t+1}=m' | X_{r}^{t}=x, M_{r}^{t}=m)$

proporciona el valor del estado interno del robot $r$ en el tiempo $t+1$ dado que en el tiempo $t$ recibió la observación $x$ y el valor de su estado interno fué $m$.

La \textit{función de comunicación}
$Comm(x,c)= Pr(Cs_{r}^{t+1}=c | X_{r}^{t}=x)$

proporciona el mensaje de comunicación transmitido por el robot $r$ en el instante $t+1$, dado que en el tiempo $t$ recibió la observación $x$.

La figura \ref{controller} muestra el diseño de alto nivel del controlador y muestra el orden en el cual considera las transiciones de estado interno, envio y recepción de mensajes de comunicación, y selección de acciones.

\begin{figure}[h]
\begin{center}

% Define block styles
\tikzstyle{decision} = [diamond, draw, fill=blue!20, text width=8em, node distance=3cm, inner sep=0pt]
\tikzstyle{block}    = [rectangle,  draw, fill=white!20,  text width=22em, rounded corners, minimum height=4em]
\tikzstyle{blockc}   = [rectangle, draw, fill=white!20,  text width=22em, text centered, rounded corners, minimum height=4em]
\tikzstyle{line}     = [draw, -latex']

\begin{tikzpicture}
  \node[scale=0.6]{
    \begin{tikzpicture}[node distance = 2cm, auto][scale=2,transform shape]
        % Place nodes
        \node [blockc]                    (expert)   {Execute\_Controller()};
        \node [blockc, below of=expert]   (init)     {$m \leftarrow m_{0}$};
        \node [blockc, below of=init]     (identify) {$x \leftarrow $ current observation};
        \node [blockc, below of=identify] (evaluate) {$c_{r} \leftarrow $ communications being received};
        \node [block, below of=evaluate]  (decide)   {$\textbf{IF}$ $\exists m'(IState(x,m,c,m'))>0$\\
                                                              $\qquad m\leftarrow m'$ with  prob.  $IState(x,m,c,m')$};
        \node [block, below of=decide]    (comm)     {$\textbf{IF}$ $\exists c(Comm(x,c))>0$\\
                                                              $\qquad$ send communication $c$ with prob. $Comm(x,c)$};
        \node [block, below of=comm]      (act)      {$\textbf{IF}$ $\exists a(Act(x,m,c_{r},a))>0$\\
                                                              $\qquad$ execute action $a$ with prob. $Act(x,m,c_{r},a)$\\
                                                              \textbf{else}\\
                                                              $\qquad$ execute desired competency actions};
        % Draw edges
        \path [line] (expert)   -- (init);
        \path [line] (init)     -- (identify);
        \path [line] (identify) -- (evaluate);
        \path [line] (evaluate) -- (decide);
        \path [line] (decide)   -- (comm);
        \path [line] (comm)     -- (act);
        \path [draw, to-] (identify.east) -| (5,-14) -| (act.south);
    \end{tikzpicture}
  };
\end{tikzpicture}

  \caption{Descripción de alto nivel del controlador} \label{controller}
\end{center}
\end{figure}

\subsection{Taxonomia del controlador MRS}

Para realizar la taxonomía del controlador se tienen en cuenta las siguientes características:

\begin{enumerate}
 \item Selección de acción determinista o probabilista ($DAct$ o $PAct$):
 \item Capacidad de mantener un estado interno persistente  ($IS$ o $NoIS$)
 \item Capacidad de comunicación inter-robot o sin comunicación ($Comm$ o $NoComm$)
\end{enumerate}

Por lo tanto un MRS compuesto por robots sin estado, sin comunicación que utilizan acciones determinísticas se rotulan: \textit{DAct-NoIS-NoComm}. El rótulo para un sistema MRS compuesto por robots sin comunicación, que utilizan acciones probabilísticas y que mantienen un estado interno es \textit{PAct-IS-NoComm} 

En el primer eje de la taxonomía se describe la naturaleza de la función de acción del robot, esta puede ser:
\\
$Deterministica: \forall{x}\forall{m}\forall{c}\forall{a}(Act(x,m,c,a) = 0 \vee Act(x,m,c,a)=1) $\\ 
$Probabilistica:  \forall{x}\forall{m}\forall{c}\forall{a}(Act(x,m,c,a)\rightarrow [0,1])$\\

El segundo eje de la taxonomía define si el robot mantiene de forma individual el estado interno o no. Dicho estado interno es una memoria temporal que pude ser modificada por el robot y es utilizada en las decisones de control. El tercer eje determina si el robot es capáz o no de comunicarse directamente con otros robots.


\subsection{Diseño del Controlador}

\subsubsection{Análisis y Definición del modelo}

El análisis toma como entrada un controlador (obtenido mediante los métodos de síntesis) y como salida predice el comportamiento de dicho controlador. Como puede verse en la figura \ref{glob_meth} el proceso síntesis y análisis es iterativo con el fín de encontrar un controlador con el comportamiento deseado. El módulo de análisis puede ser utilizado como una herramienta predictiva para entender el comportamiento esperado del sistema y de esta forma determinar donde y porque falla un determinado diseño. Adicionalmente, el análisis puede ser utilizado como ayuda en el proceso de diseño, en la toma de decisiones relacionadas al uso apropiado del estado interno o de la comunicación entre robots.

En este estudio se utilizó un modelo de análisis probabilístico microscópico, es probabilística ya que los robots son modelados como procesos paralelos que operan en un entorno común modelados como una serie de eventos estocásticos. Los robots son modelados como procesos separados y la salida del modelo es el resultado de la interacción entre los robots y entre los robots y el entorno. \cite{AJI+01} \cite{MIM99}. 


En el modelo macroscópico \cite{KLAM04} se trata el grupo de robots como un todo indivisible, derivando el comportamiento a nivel de sistema de forma directa sin tener en cuenta las interacciones entre robots.

Este método toma como entrada un mundo \textit{W}, una tarea \textit{T}, y un grupo de robots \textit{R}. Todos los robost ejecutan controladores idénticos que estan formados por una función de acción \textit{Act}, una función de transición de estado interno \textit{IState} y una función de comunicación \textit{Comm}. Visto desde un nivel de descripción alto, el proceso realiza diferentes ensayos de Monte Carlo independientes de la tarea T, estos ensayos se repiten hasta que se cumpla la tarea o hasta cuando se presente una acción incorrecta y la tarea termine de forma no satisfactoria.

El proceso comienza inicializando dos contadores \textit{count\_correct} y \textit{count\_incorrect}, los cuales representan el número de ensayos de las tareas correctos e incorrectos respectivamente. Cada ensayo comienza con la inicialización del estado interno de todos los robot y el estado del mundo \textit{s} al estado inicial $u\_start_T$ de la tarea \textit{T}, después se entra a un ciclo que se repite hasta que el estado del mundo sea igual al estado final $u\_term_T$ de la tarea \textit{T}, o hasta que se ejecute uan acción incorrecta. En el primer caso, se terminan los ensayos y se actualiza el valor de \textit{count\_correct}, para el segundo caso, se terminan los ensayos y se actualiza el valor de \textit{count\_incorrect}.


\subsubsection{Síntesis del Controlador}

La síntesis permite la creación de una instancia del controlador que cumpla con las especificaciones, con el grado de desempeño deseado mientras satisface las restricciones impuestas por las capacidades de los robots. Normalmente estos controladores son construidos a mano utilizando la experiencia del diseñador, el aporte de este trabajo permite que dicho controlador sea creado de forma automática. El controlador construido utiliza diferentes combinaciones de características de control del siguiente grupo:

\begin{itemize}
  \item Selección de acción deterministico o probabilistico
  \item Mantenimiento del estado interno o sin estado.
  \item El uso de comunicación entre robots o sin comunicación.
\end{itemize}

De las posibles combinaciones de estas características de control se generaron cuatro métodos de síntesis, ver figura \ref{meth}:
\begin{figure}[H]
 
\begin{center}

\tikzstyle{sensor} = [draw, fill=blue!20, text width=15em, text centered, minimum height=2.5em]
\tikzstyle{naveqs} = [sensor, text width=9em, fill=blue!20, minimum height=3em, rounded corners]
\begin{tikzpicture}
  \node[scale=0.6]{
    \begin{tikzpicture}
        \node (node0)                              [naveqs] {DAct-IS-NoComm};
        \path (node0.east)+(3,0)      node (node1) [naveqs] {DAct-IS-Comm};
        \path (node0.south)+(0,-2)    node (node2) [naveqs] {PAct-Is-NoComm};
        \path (node1.south)+(0,-2)    node (node3) [naveqs] {PAct-Is-Comm};

        \path (node0.north west)+(-1,1.5)  node (node4) [naveqs] {DAct-NoIS-NoComm};
        \path (node2.south west)+(-1,-1.5) node (node5) [naveqs] {PAct-NoIS-NoComm};
        \path (node1.north east)+(1,1.5)   node (node6) [naveqs] {DAct-NoIS-Comm};
        \path (node3.south east)+(1,-1.5)  node (node7) [naveqs] {PAct-NoIS-Comm};

        \draw [-to, dashed] (node0.east)  -- (node1.west);
        \draw [-to, dashed] (node2.east)  -- (node3.west);
        \draw [-to, dashed] (node0.south) -- (node2.north);
        \draw [-to, dashed] (node1.south) -- (node3.north);

        \draw [-to, dashed] (node4.east)  -- (node6.west);
        \draw [-to, dashed] (node5.east)  -- (node7.west);
        \draw [-to, dashed] (node4.-120)  -- (node5.120);
        \draw [-to, dashed] (node6.-120)  -- (node7.120);

        \draw [-to, dashed] (node4.-20)   -- (node0.156);
        \draw [-to, dashed] (node5.20)    -- (node2.-156);
        \draw [-to, dashed] (node6.-156)  -- (node1.20);
        \draw [-to, dashed] (node7.156)   -- (node3.-20);

    %     \draw [-to] (naveq.east)+(.6,0) .. controls +(right:1.5cm) and +(up:1cm) ..     (coord.20) ;
    %     \draw [to-] (synt.west)+(-.6,0) .. controls +(left:1.5cm) and +(down:1cm) ..   (defini.-160) ;
    % 
    \end{tikzpicture}
  };
\end{tikzpicture}
  \caption{Metodología de Diseño de controladores para un MRS.} \label{meth}
\end{center}
\end{figure}

\begin{enumerate}
  \item \textbf{Selección de acción determinística, sin estado interno, sin comunicación NoIS-NoComm} Este es el caso más sencillo, la función de definición de acción es un mapero directo de observación a acción. El proceso de síntesis comienza con la inicialización de las funciones de transición de estado, comunicación y acción a cero para todas las circunstancias; con esto, el controlador es incapáz de realizar transiciones de estado interno, comunicaciones o acciones. A continuación, el proceso de síntesis adiciona una regla a la función de acción de la forma $Act(x,*,\{*\},a)=1$ tal que $x$ es observable en $u$ y $P(u,a,v) > 011$
  \\ Este método no garantiza una probabilidad óptima de correcta ejecución de tareas. El método mapea todas las observaciones y acciones que tienen la oportunidad de ser correctas para un estado de tarea dado. Su principcdal inconveniente esta en situaciones que involucran \textit{perceptual aliasing}; \textit{Perceptual aliasing} es la condición en la cual, una observación $x$ puede ser realizada en dos estados diferentes $S_i$ y $S_j$. Si no existe una acción $a$ en la cual $x$ y $a$ son correctas para $s_i$ pero no para $s_j$ no hay problema. Si dicha acción existe entonces se ejecutará correctamente en $s_i$ pero de forma incorrecta en $s_j$.
  
  \item \textbf{Selección de acción determinística, con estado interno, sin comunicación DAct-IS-NoComm} El proceso de síntesis se realiza en cuatro pasos: 1) Sintetizar un controlador NoIS-NoComm 2) Para cada estado de la tarea, identificar las acciones y observaciones usadas en la función de acción en el DAct-NoIS-NoComm, considerar todos los caminos para una correcta ejecución de tareas. 3) Identificar el uso de l estado interno para tratar con observaciones implicadas en \textit{perceptual aliasing}. 4)Identificar ramas en la definición de tarea e insertar una transición de estado interno para distinguir los valores de estado interno a través de las ramas.
  
  \item \textbf{Selección de acción determinística, sin estado interno con Comunicación DAct-NoIS-Comm} El proceso de síntesis se realiza en cuatro pasos: 1) Sintetizar un controlador NoIS-NoComm 2) Identificar las situaciones donde puede usarse la comunicación para aumentar el deseméño. 3) Asignar mensajes de comunucación específicos a cada una de estas situaciones, utilizando un grafo de colores. 4) Aumentar de forma adecuada las funciones de acción y comunicación proporcionadas por el controlador DAct-NoIS-Comm.
  
  \item \textbf{Seleción de Acción Probabilística, sin estado interno, sin comunicación PAct-NoIS-NoComm} Para la síntesis de este controlador se utilizó un algoritmo genético (GA). Determinar de forma analítica las probabilidades óptimas para cada elemento de la función de acción es un problema altamento no-lineal, por tanto insoluble; El GA no garantiza una solución óptima, pero, es capáz de sintetizar un controlador PAct-NoIS-NoComm con una mayor probabilidad de corección de ejecución de la tarea que el controlador DAct-NoIS-NoComm. Existen tres pasos en el proceso de síntesis: 1) Sintetizar un controlador DAct-NoIS-NoComm, 2) Inicializar la población de cromosomas representando soluciones potenciales, 3) Evolucionar de forma iterativa la población para encontrar una solución mejorada, utilizando los mecanismos de selección Elitismo, mutación y crossover.
\end{enumerate}
 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Marco de Trabajo Basado en la Inmunidad para Control Multi-agente Distribuido \cite{HYKL06}} 

Especificidad, inducibilidad, diversidad, memoria, distinción entre propio y no propio (non self), autoregulación; son las principales características del sistema inmune humano, y las que permiten que utilizarlo en la solución de problemas en ingeniería.

El marco de control organiza un grupo de agentes en un entorno dinámico, se desarrolla con base en el mecanismo distribuido de la inmunidad biológica. El Sistema Inmune (SI), es un tipo especial de sistema multi-agente donde cada elemento inmune tiene un patrón de comportamiento y funciones específicas para un antígeno particular. El comportamiento de dicho agente, depende del entorno, así como del comportamiento individual; además posee un grupo de capacidades específicas que determinan su inteligencia fundamental. Esta inteligencia puede ser alcanzada através de comunicación entre agentes o através de exploraciones del entorno.

Se adoptó una red de control distribuida basada en el comportamiento, la cual se basa en la transición de estado de comportamiento de los agentes; la operación de los agentes no está predeterminada, pero se altera dinámicamente con el fín de adaptarse a un entorno de trabajo dinámico. Este control distribuido y no-determinísstico herada las siguientes funciones del sistema inmune humano:

\begin{enumerate}
 \item \textbf{Auto-organización} Los agentes tienen la capacidad única de determinar respuestas para alcanzar objetivos comunes a través de toma de decisiones indepenientes y utilizando comunicaciones.
 \item \textbf{Reconocimiento de Self/Non-self} Los agentes identifican tareas durante su exploración aleatoria; para evaluar la estimulación de una tarea específica se utiliza la función de afinidad (un índice para identificación non-self). Este reconocimiento depende únicamente de la estimulación proporcionada por la tarea, los agentes no poseen información previa sobre su localización o complejidad. Cada agente posee un set predefinido de capacidades, lo cual los hacen extremadamente flexibles para abordar diferentes tipos de problemas.
 \item \textbf{Adaptabilidad} Los agentes ajustan sus comportamientos al atacar un problema manipulando la mejor respuesta, evaluando la especificidad de sus capacidades. Se adquieren nuevos conocimientos o funcionalidades cuando se enfrentan a variaciones de tareas y entorno.
 \item \textbf{Robustez} La falla de un agente, mientras ejecuta una operación no paralizará el sistema; ya que el marco de control está encaminado a ser totalmente decentralizado y no se asignan dependencias fijas entre tareas y agentes.
 \item \textbf{Diversidad} El sistema es capáz de aprender de la experiencia, manipulando sus capacidades y realzando su inteligencia fundamental para resolver diferentes problemas.
\end{enumerate}

El marco de control proporciona un grupo de reglas que guían y determinan el comportamiento de un agente en respuesta a un entorno dinámico. Através de la manipulación de las reglas se pueden investigar de forma efectiva eventos desconocidos y variaciones dinámicas del sitio de trabajo. La figura \ref{control_flow} muestra el flujo de control de un agente SI. Primero realizan una exploración del entorno circundante dentro de su rango sensorial ($SR_S$). Basándose en la medición de afinidad, los agentes reconocen y se enfocan en una tarea. Una vez reconocida una tarea, el agente manipula sus capacidades con una función que recibe el nombre de \textit{matching específico} esto permite que el agente realice respuestas apropiadas al abordar diferentes tareas. Se definen cuatro tipos de respuestas inspiradas en el sistema inmune, ellas son: No específicas, específicas, adquiridas y pasivas. La respuesta no específica se encarga de tareas generales, los agentes ejecutan capacidades predefinidas cuando abordan este tipo de tareas; para tareas más complicadas, los agentes requieren la generación de nuevas capacidades específicas a estas tareas, los agentes modifican sus capacidades fundamentales para abordar este tipo de tareas, estas nuevas capacidades son almacenadas en memoria en la forma de respuesta adquirida. La respuesta pasiva se presenta en tareas que requieran cooperación de más de un agente, es este caso, el primer agente que solicita ayuda es el único que puede dar instrucciones a los otros agentes, los cuales exhiben un comportamiento pasivo \cite{HYKL06}.


\begin{figure}[ht]
\begin{center} \includegraphics[scale=.5]{./images/sia_arch}   \end{center}
\caption{Flujo de control de un agente del sistema inmune} \label{control_flow} 
\end{figure}

\subsection{Modelo Matemático}
Los atributos básicos de un marco de trabajo Sistema Inmune Artificial (SIA) incluyen un grupo de agentes que operan en el sistema ($A_j$), un grupo de tareas ($G_i$) que se encuentran localizadas en el sitio de trabajo ($Env=a_j \cup g_i  \forall i,j$), un rango sensorial ($SR$) de un agente que le permite adquirir o recibir información del entorno, y un rango de comunicaciones ($CR$) que premite el intercambio de información y/o mensajes entre agentes.

\subsubsection{Binding Affinity}
En la inmunidad biológica, la distancia no es lo único que concierne a la afinidad; la afinidad entre un anticuerpo y un antígeno involucra muchos procesos como reconocimiento de patrones, interacciones no covalentes, etc. De igual forma la función \textit{binding affinity} entre un agente y una tarea, está formada por tres parámetros: La distancia Manhattan ($d_{ij}$), la frecuencia de ocurrencia de la tarea y la función \textit{specificity matching} \footnote{Esta función compara cadenas con el fín de determinar el mejor  \textit{match} entre una tarea y el grupo de agentes disponibles}. La frecuencia de ocurrencia de tareas puede aumentar la afinidad entre un agente y un tipo particular de tarea, al evaluar el número de veces que un agente ha terminado de forma satisfactoria dicha tarea en el pasado, por lo que los agentes tienden a moverse a tareas más familiares.

$f_{ij}=\frac{O_i}{\displaystyle\sum_{x=1}^m O_x}$

donde: $O_i$ es el número de ocurrencias de la tarea  \textit{i} 

La función \textit{specificity matching} ($r_{ij}$) sigue el concepto de reconocimiento de patrones en la inmunidad biológica, y verifica la factibilidad para que un agente maneje una determinada tarea. En la naturaleza, el SI reconoce a los antígenos por su estructura, en este modelo, se transforma la complejidad de la tarea en códigos de tal forma que los agentes puedan compararlos con sus capacidades.

$r_{ij}=\frac{1}{R_{I}^S \centerdot R_L}$

donde: $R_I$ es el índice para inteligencia relativa entre un agente y una tarea. $R_L$ es una medida de compatibilidad de matching entre la capacidad de un agente y la tarea; y $S$ es el puntaje relativo que resulta de la eficiencia entre la capacidad y la especificación de la tarea.

$\beta_{ij}=f(d_{ij}, f_{ij}, r_{ij})$ \\
$\beta_{ij}=\omega_1{(d_{ij})}^{-1} + \omega_2(f_{ij}) + \omega_3(r_{ij})$

donde $d_{ij} = \mid{x_i + x_j}\mid + \mid{y_i - y_j}\mid$

\subsection{Modelos de Cooperación}

\subsubsection{Estados de Conmportamiento de un agente SIA}
  La cooperación entre agentes SIA es el resultado de la comunicación y de interacciones simples, los procesos de comunicación son controlados por el comportamiento interno de los agentes. En la tabla \ref{states} se definen algunos estados de comportamiento y sus estrategias correspondientes, estos estados permiten que los agentes conozcan las estrategias de los demás.
\begin{center}
  \begin{table}[ht]
  \begin{tabular}{|l|c|p{10cm}|}
    \hline
     \textbf{Estado} & \textbf{Notación} & \textbf{Descripción}  \\ \hline
     Achieve   &   Ach    & Abordar la tarea sleccionada  \\ \hline
     Agitate   &   Ag     & Una tarea ha sido encontrada y el agente se enfoca en su objetivo. \\ \hline
     Cooperate &   Co     & Ofrece ayuda y participa en un trabajo cooperativo  \\ \hline
     Disperse  &   D      & Mantenerse Alejado de otros agentes si el número de agentes dentro de la zona
                            de exploración excede un umbral.\\ \hline
     Explore   &   E      & Explora el entorno circundante de forma aleatoria en búsuqeda de tareas \\ \hline
     Idle      &   I      & Espera a otros agentes para abordar una tarea de cooperación \\ \hline
     Reply     &   Rp     & Recive la señal \textit{help} de otro agente.\\ \hline
     Request   &   Rq     & Solicita ayuda de otros agentes.\\ \hline
  \end{tabular}
  \caption{Estados de Comportamiento de un Agente SIA} \label{states} 
  \end{table}
 
\end{center}

El diagrama de transición de estados dado en la Figura \ref{State_flow} muestra el comportamiento de los agentes en respuesta al entorno dinámico. Los agentes cooperan a través de las señales de estrategias de ayuda \textit{request for} y \textit{respond to}. Un agente que trabaja en una tarea cooperativa y requiere ayuda de otros recibe el nombre de \textit{agente iniciador}. Un agente que recibe la señal de ayuda de un agente iniciador y que responde a este llamado recibe el nombre de \textit{responding agent} Este concepto es similar al Sistema Inmune Humano, donde las células inmunes son activadas dependiendo del tipo de antígeno. La identificación del estado comportamental es vital para determinar la viabilidad de la capacidad de un agente para ofrecer ayuda. Un agente que se encuentra en los estados \textit{explore} o \textit{disperse} es capaz de ofrecer ayuda y de ser activado por una señal de ayuda, de lo contrario el agente ignorará el llamado y continuará con su trabajo actual. A continuación se muestra la descripción matemática del modelo de comunicación.

El j-ésimo agente $a_{j}^{CR_x}$ que está dentro del rango de comunicación $CR$ del agente $x$ $(CR_x)$ se define como:
\\
$a_{j}^{CR_x} \doteq \mid d_{xj}(M)\mid < CR_x$

El grupo de agentes $A^{CR_x}$ que se encuentra dentro del rango de comunicación del agente $x$ se define como:
\\
$A^{CR_x}=\{a_j \in a \mid a_j^{CR_x}\}$
\\
$\exists A^{CR_x}\in a_j$   $a_j^{CR_x} \wedge \neg (a_x)$

La señal de ayuda $h_x^i$ enviada por el agente $x$ para la i-ésima tarea se define como:
\\
$h_x^i=(a_x,g_i)$    $\forall A^{CR_x}$

La señal de respuesta $r_j^i$ enviada por el agente $j$ con relación a la solicitud de un agente $x$ se definie como:
\\
$r_j^i=(a_j,g_i,h_x^i)$    $\forall a_{j}^{CR_x}(E \cup D)$


\subsection{Interacción Entre Agentes SIA}
Se puede investigar la interacción entre agentes SIA utilizando los cambios de sus estados de comportamiento. Existen dos tipos de interacciones: las restricciones de concentración y la cooperación. El concepto de restricciones de concentración está inspirado en la teoría auto-regulatoria de la inmunidad humana, la cual proporciona un mecanismo de regulación para controlar la concentración de anticuerpos via estimulación y supresión de la respuesta inmune. El SI produce anticuerpos cuando se presenta un antígeno y regresa al equilibrio cuando estos han sido removidos.

Asumiendo que hay $n$ agentes explorando el entorno y el umbral de concentración en la zona de exploración es $\tau$, los cambios estratégicos de comportamiento con restricciones de concentración son:
\\
$na(E) \rightarrow (n - \tau)a(D) \wedge \tau a(E)$       si  $n >  \tau$
Lo que nos indica que cuando el número de agentes exploradores es mayor que el umbral de concentración, únicamente  $\tau$ agentes se encuentran en estado de \textit{explore}, los restantes, $n - \tau$ deben cambiar al estado \textit{Disperse} y alejarse de esa zona de exploración.
\\
$na(E) \rightarrow na(E)$        si  $n \le  \tau$
Por el contrario, si el número de agentes en la zona de exploración es menor que el umbral de concentración, todos los agentes se encuentran en el estado \textit{explore}.

Cuando un agente $x$ no puede completar una tarea por si solo, envía una señal de auxilio para activar a los agentes próximos a él, el agente $x$, por lo tanto, se encuentra en el estado \textit{request} $a_x(Rq)$. El agente que responde a este llamado $a_{j}^{CR_x}$ y puede ofrecer ayuda se define como:
\\
$ \forall a_{j}^{Rp} \in a_{j}^{CR_x}$,    $a_j(E \wedge D)$

La actividad de cooperación con control comportamental estratégico entre agentes SIA está definido como:
\\
$[a_x(Rq) \wedge a_y(Ry)] \rightarrow [a_x(I) \wedge a_y(Co)]$\\
El agente $x$ se encuentra en estado \textit{request} cuando envía la señal de auxilio, después cambia a estado \textit{idle} mientras llega la ayuda. El agente $y$ que responde a esta solicitud se encuentra en el estado \textit{reply} cuando recibe la señal y cambia al estado \textit{Cooperate} para ofrecer ayuda.
\\ 
$[a_x(I) \wedge a_y(Ag)] \rightarrow [a_x(Ach) \wedge a_y(Ach)]$\\
Inicialmente el agente $x$  se encuentra en estado \textit{Idle} esperando por ayuda, mientras que el agente $y$ se encuentra en estado \textit{agitate} aproximándose a la tarea cooperativa. Después el agente $y$ llega al sitio de la tarea cooperativa y la termina en el estado \textit{Achieve}.


\begin{figure}[ht]
\begin{center} \includegraphics[scale=.5]{./images/State_Transition_SIA}   \end{center}
\caption{Modelo de Transición de Estados de un agente SIA} \label{State_flow} 
\end{figure}


\subsection{Umbral de Afinidad}

El umbral de afinidad ($K_i$), es un valor dinámico que controla la activación o supresión de un agente al abordar una tarea $i$, de acuerdo con su índice de afinidad. Cuando la afinidad entre el agente $j$ y la tarea $i$ ($\beta_{ij}$) excede el valor de $K_i$, la actividad es permitida, de lo contrario es suprimida. Este umbral esta definido por: \\

$K_i=\frac{\displaystyle\sum_j{\beta_{ij}}}{\eta_{ij}\cdot \eta_{req} }$

donde: \\
$\beta_{ij}$ Es la \textit{afinidad} del agente $j$ para la tarea $i$\\
$\eta_{ij}$  Es el número total de agentes calificados que detectaron la tarea $i$\\
$\eta_{req}$ Es el número total de agentes que se requiere para abordar la tarea $i$\\



\subsection{Manipulación de la Respuesta del Marco de Control Basado en SIA}



\subsubsection{Cadena de Capacidades y Complejidades}

La estructura básica de todos los anticuerpos consta de dos pares de cadenas \textit{pesadas} y \textit{ligeras} (heavy \& light). la cadena pesada denota la calse del anticuerpo y especifíca la clase de respuesta, mientras que la ligera es distintiva antigénicamente y solo esta presente en una molécula de anticuerpo; la cadena ligera consiste de una serie de habilidades atómicas y es distintiva para cada respuesta. Esto se hace para imitar la estructura de un anticuerpo y para formar la cadena de capacidades para cada respuesta identificada en el marco de control.

Por otro lado, una tarea se representa como una cadena de complejidades, la cual tiene la misma estructura de la cadena de capacidades, de igual forma, la cadena ligera define la complejidad de la tarea. La complejidad especifica, las capacidades requeridas por un agente para abordarla; con el fín de verificar la factibilidad de un agente para realizar una tarea se utiliza la función de \textit{matching específico}, la cual compara las cadenas ligeras de capacidades y complejidades.

La figura \ref{capability_man_process} define la forma en la que el agente de forma autónoma determina la respuesta apropiada  cuando encuentra una tarea. Las tareas están divididas en ordinarias y cooperativas, las primeras pueden ser manejadas por un agente, mientras las cooperativas requieren más de un agente. Primero el agente verifica si la tarea requiere cooperación o no, si es una tarea cooperativa el agente se comunica con el agente \textit{iniciador} y realiza una respuesta pasiva, de lo contrario, si se trata de una tarea simple, chequea la capacidad de las cadenas no específicas y adquiridas, si no se encuentran coincidencias, el agente manipulará sus habilidades atómicas (en la cadena no-específica) para realizar una respuesta específica.

\begin{figure}[ht]
\begin{center} \includegraphics[scale=.5]{./images/response_man_algorithm}   \end{center}
\caption{Algoritmo de manipulación de respuesta} \label{response_man_algorithm} 
\end{figure}

\subsection{Metodología de Coincidencia Específica}

En inmunología, la activación de células inmunes (linfocitos) es activada por el reconocimiento de antígenos. Los linfocitos reconocen a los antígenos de forma estructural; siguiendo este concepto, de reconocimiento de patrones, se desarrolló un algoritmo de \textit{string matching} para comparar tareas y agentes, utilizando sus correspondientes cadenas de complejidad y capacidad. Las cadenas ligeras de agentes y tareas son comparadas con el fín de determinar si el agente es apto para manejar la tarea objetivo. En el \textit{matching específico} se investigan primero las cadenas de capacidades no-específicas (00) y adquiridas (01) ya que ellas proporcionan una respuesta rápida al método \textit{absolute string-matching} (Figura \ref{string_matching}), el cual, determina si el string completo de una cadena ligera de complejidades de una tarea puede encontrarse en la cadena ligera de capacidades de un agente y dar un resultado definitivo si las cadenas coinciden o no.

\begin{figure}[ht]
\begin{center} \includegraphics[scale=.5]{./images/string_matching}   \end{center}
\caption{Algoritmo \textit{Absolute String Matching}} \label{string_matching} 
\end{figure}


 Cuando no se encuentran coincidencias de las respuestas no-específica y adquirida, se inicia un proceso de recombinación y re-acomodación de las habilidades básicas elementales, para generar un nuevo grupo de capacidades espacíficas a esta nueva tarea,
ver Figura \ref{capability_man_process}.

\begin{figure}[ht]
\begin{center} \includegraphics[scale=.5]{./images/capability_man_process}   \end{center}
\caption{Secuencia del proceso de manipulación de capacidades} \label{capability_man_process} 
\end{figure}


\subsubsection{Lógica de Control}
Haciendo un paralelo con el Sistema Inmune humano, el \textit{self} y \textit{non-self} de este marco de control corresponden a los agentes y las tareas. Los agentes SIA comienzan el ciclo de operación realizando movimientos pseudo-aleatorios; este modo de exploración libre permite a los agentes SIA identificar y aproximarse al \textit{non-self} (tareas) . Si el número de agentes SIA exploradores en la zona de exploración excede un umbral que define el \textit{sobrecupo} dentro de dicha zona, los agentes se dispersarán con el fín de mantener una exploración eficiente. Una vez que un agente SIA sense una tarea, utilizará la función \textit{binding affinity} para reconocerla y aproximarse a ella. Esta función evalúa los factores físicos y especificidad de un agente para abordar la tarea. La figura \ref{control_logic} muestra la lógica de control del marco.

\begin{figure}[ht]
\begin{center} \includegraphics[scale=.35]{./images/control_logic}   \end{center}
\caption{Lógica de Control de un marco de control basado en ASI} \label{control_logic} 
\end{figure}


\subsubsection{Comportamiento de un Agente SIA}
Un agente SIA altera su comportamiento monitoreando el entorno; los diferentes estados y sus estrategias correspondientes se muestran en la tabla \ref{states}. Para abordar una tarea, una agente SIA exhibe diferentes comportamientos, los cuales se representan en la Figura \ref{State_flow}. Los cambios de estado son gobernados por un grupo de reglas evento-condición-acción, dichas reglas permiten que los agentes SIA realicen respuestas bajo diferentes situaciones; de acuerdo con estas reglas, los agentes obtienen información através de comunicación entre ellos, esta información incluye localización de tareas, señales de auxilio, y estados de comportamiento de otros agentes; toda esta información permite a los agentes coordinar planes de acción para diferentes tipos de tareas. La Figura \ref{Decision_tree} muestra el árbol de decisiones que define las acciones de los agentes SIA, este árbol muestra como los agentes se adaptan a cambios en el entorno y se comportan de forma autónoma al abordar las tareas.

\begin{figure}[ht]
\begin{center} \includegraphics[scale=.55]{./images/Decision_tree}   \end{center}
\caption{Arbol de decisiones que define las acciones de un agente SIA} \label{Decision_tree} 
\end{figure}



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%



\section{Sistema de Navegación Autónoma de Robots con Feromonas Artificiales}

Algunos instectos sociales como las hormigas, muestran un gran desempeño en diversas actividades \cite{Holl90}. No existe un control central en estas comunidades. Son capaces de determinar la localización de comida con la ayuda de sustancias químicas llamadas feromonas, la feromona, es dejada en la superficie de la tierra para una movilización eficiente. Las hormigas construyen caminos utilizando feromonas para formar redes que conectan su nido con las fuentes de comida. El primer camino creado no es el óptimo, sin embargo, los caminos más cortos recibirán mayor concentración de feromonas (debido a que el tiempo requerido para recorrerlo es menor) y en los más largos la concentración de feromonas se reducirá. \cite{Her07} Esto es muy interesante desde el punto de vista de comunicación multi-agente ya que un agente puede dejar múltiples mensajes en el entorno. Este tipo de sistema de comunicación indirecta no solo omite la comunicación centralizada, sino que establece una relación entre información y posición en el entorno.\cite{Kur99}. Este fenómeno ha sido estudiado en varios campos de investigación \cite{EL94} \cite{PDDM+01} \cite{SKKT04} \cite{PHVD97}. Debido a que las feromonas son sustancias químicas, son difíciles de utilizar en aplicaciones reales.

Algunos investigadores han utilizado el concepto de feromona virtual para imitar las características de las feromonas, \cite{SKKT04} \cite{TKYI+05} \cite{MMQR06}, a continuación se realizará una breve descripción del trabajo relizado en \cite{MMZF05} y \cite{Her07} los cuales, raelizan implementaciones reales que se aproximan a las características que se desean extraer de las feromonas. Estos trabajos utilizan la tecnología RFID como medio para simular las feromonas. Esta tecnología utiliza variaciones de campo magnético para la comunicacion. Tiene 2 componentes principales, los \textit{tags} y los \textit{readers}. Un tag es un dispositivo de identificación que posee un identificador único y una pequeña cantidad de memoria disponible. Un \textit{reader} es un dispositivo que puede reconocer la presencia de un \textit{tag} y hacer operaciones de lectura y escritura sobre él.

\subsection{Implementación de Feromonas Digitales Utilizando RFID \cite{MMZF05} \cite{MMZF07}}

Las principales fortalezas de la interacción con feromonas se basan en dos puntos claves:
\begin{enumerate}
 \item Desacopla las interacciones entre agentes haciéndolas adecuadas en entornos abiertos y dinámicos donde los agentes no se conocen entre si y pueden ir y venir en cualquier momento.
 \item Soporta aplicaciones de contexto específico, en las que las feromonas proporcionan a los agentes una representación específicas a la aplicación de su entorno operacional. Por ejemplo, en recolección de comida, las feromonos proporcionan una representación del entorno en forma de caminos a fuentes de comida.
 \item Permite la adaptación de actividades, las feromonas representan una información contextual que si no se actualiza, desaparece.
 \item Los algoritmos que involucran la interacción basada en feromonas son simples e involucran interacciones locales únicamente.
\end{enumerate}

Se han creado muchas aplicaciones multi-agente inspiradas en estos conceptos, \cite{OBHM02} \cite{EBMD99} \cite{RMRT03} \cite{VPSB04}, sin embargo, ninguna de ellas propone soluciones válidas para utilziar feromonas en aplicaciones reales. En este trabajo se propone una versión de feromona basada en tags de RFID \cite{RW04}, explotando su característica de poder ser escritos en cualquier momento por dispositivos inalámbricos que reciben el nombre de \textit{readers}, los cuales, al ser llevados por un agente robótico, pueden describir caminos de feromonas a través del entorno, almacenando los valores de las feromonas en los tags RFID localizados allí, a medida que el usuario se desplaza a través del entorno.


Los Tags RFID son dispositivos ampliamente utilizados en la actualidad y gracias al avance de la industria de los semiconductores pueden ser tan pequeños como un grano de arróz, no requieren baterías, se energizan únicamente cuando un \textit{reader} se encuentra cerca, estos \textit{readers} poseen una antena que utilizan para inducir un campo electromagnético en el tag y de esta forma alimentar su circuito interno, este campo electromagnético también se utiliza como medio de comunicación entre el tag y el \textit{reader}. El radio de alcance del \textit{reader} depende de la potencia del campo magnético inducido por la antena, y de la forma de la misma, en nuestro caso es suficiente con un rango del orden de los centímetros. Cada tag posee un identificador único (debido a que fueron creados para identificación) y una pequeña cantidad de memoria no volátil que permite ser modificada en cualquier momento.

\subsubsection{Desarrollo de la Feromona}
Cada agente debe llevar consigo un reader RFID, con lo que puede detectar los tags distribuidos en el entorno (los cuales reciben el nombre de \textit{tags de localización}), y puede escribir en todos ellos estructuras de datos de feromona (formadas por lo menos por un identificador de feromona); este proceso crea caminos de feromonas digitales a lo largo de los \textit{tags de localización}.

Llamemos $L(t)$ el grupo de \textit{tags de localización} detectados en el tiempo $t$. Es posible detectar el movimiento del agente si $L(t) \neq L(t-1)$. Para la mayoría de las aplicaciones, un camino de feromonas formado únicamente por identificadores (IDs) no resulta útil, en la naturaleza, las hormigas utilizan estos caminos de feromonas para determinar el origen y destino de dichos caminos. Basándose en la información de los IDs, no puede determinar la dirección del camino, lo cual no proporciona información útil al agente. Para resolver este problema, es necesario, almacenar en cada estructura de datos de la feromona un contador $C(O)$ asociado a la feromona $O$.

Si un agente desea difundir una feromona $O$ en el tiempo $t$, el agente inicializa un contador a 0. Cuando se detecta movimiento $L(t) \neq L(t-1)$ se debe leer el valor de $C(O)$ en el grupo $L(t)$, si $C(O)$ no existe, lo inicializa a cero. Después de un movimiento, el agente almacenará $O$ y $C(O)+1$ en los tags que pertenecen a $L(t+1)$ que no tienen $O$ o que tienen un valor menor en $C(O)$.

\begin{figure}[ht]
\begin{lstlisting}[caption={Algoritmo de propagación de feromona}, numbers=none]
hop = 0;
while(true) {
  if(L(t)!=L(t-1) {
    new = read(C(O));
    if(new == null || new < hop)
      write(C(O)=hop);
    else
      hop = new;
    hop++;
  }
}
\end{lstlisting}\label{alg_prop_fero}
\end{figure}

Adicionalmente, la idea básica de feromona requiere un mecanismo de evaporación, para descartar los caminos viejos y posiblemente dañados; para esto se almacena una valor $T(O)$ que representa el tiempo cuando fué almacenada la feromona. Para sistemas distribuidos es significativo únicamente si los agentes están sincronizados, sin embargo, una sincronización del orden de un segundo es suficiente en este trabajo.

En la Figura \ref{mem_org_tag} se muestra la organización de la memoria de los tags RFID, cada uno de ellos posee un identificador único y un arreglo de celdas de memoria, lugar donde serán almacenadas las estructuras de datos de las feromonas, en este trabajo se utilizan 3 campos para almacenar la información de cada feromona, el primero almacena el identificador de la feromona, el segundo el contador asociado y el tercero el timestamp. El primer campo disponible en la memoria es un puntero que ínice la primera posición de memoria disponible para almacenamiento. 

\begin{figure}[ht]
\begin{center} \includegraphics[scale=.5]{./images/pheromone_mem_organi}   \end{center}
\caption{Distribución de memoria de un tag RFID} \label{mem_org_tag} 
\end{figure}


\subsubsection{Lectura de la Feromona y Evaporación}

La lectura de feromonas es un proceso no muy confiable, ya que los tags RFID pueden no responder de forma adecuada, por lo tanto se deben fusionar los datos obtenidos en cada iteración; el agente decidirá la acción a ejecutar basándose en esta información. Debido a que los tags son dispositivos pasivos el agente utilizando su \textit{reader} debe realizar las siguientes operaciones:

\begin{enumerate}
 \item Leer el índice de \textit{tag[0]}.
 \item Almacenar en \textit{tag[index]} el identificador de la feromona.
 \item Almacenar en \textit{tag[index+1]} el contador de la feromona.
 \item Almacenar en \textit{tag[index+2]} el timestamp.
 \item Almacenar \textit{index+3} en \textit{tag[0]}.
\end{enumerate}


Para realizar la evaporación de la feromona, el agente debe leer el campo correspondiente al \textit{timestamp} si este valor es anterior al \textit{timestamp} del agente en un umbral $T$, se borra la feromona del TAG. Debido a que la memoria disponible en los tags es muy reducida es más conveniente alamcenar únicamente los caminos de feromonas importantes para la aplicación, los viejos se borrarán. Por lo tanto, es importante crear mecanismos que impidan la evaporación de las feromonas relevantes. Para esto, un agente que esparse una feromona $O$, puede sobre-escribir feromonas con $T(O)$ viejo, por lo que el umbral $T$ tiene que ser ajustado para cada aplicación de forma tal que refleje el intervalo de tiempo durante el cual se considera útil la feromona.

\subsubsection{Difusión Proactiva y parasitaria}

A diferencia de las feromonas reales, las cuales se difunden en el entorno siguiendo leyes físicas, la naturaleza pasiva de los tags RFID implica que las feromonas digitales pueden difundirse únicamente ante la presencia de un \textit{reader}. Por lo que no se difunden a su alrededor sino en una determinada dirección; una vez comienza la dispersión de la feromona, el camino resultante es el seguido por el agente que realizó la dispersión. El problema radica en que los otros agentes solo notarán este camino de feromonas hasta cuando se crucen con el, lo cual no es aceptable para una coordinación basada en feromonas.

Para resolver este problema, se creo una forma \textit{parasitaria} de difusión de feromonas. Una vez un agente dejó un camino de feromona, otro agente que cruza dicho camino (aún si tiene otro objetivo totalmente diferente) puede ser utilizado para difundir la feromona en otras direcciones. Es decir, la feromona de forma \textit{parásita} utiliza el \textit{reader} de agentes que estén en su camino para difundirse en diferentes direcciones. Cuando un agente difunde una feromona de forma parásita, aplica un algorítmo como el algoritmo \ref{alg_prop_fero}, pero disminuye el valor de $C(O)$; lo cual crea un camino de feromona que lleva al punto donde la feromona fue difundida originalmente.

El bit \textit{Diff} en la estructura de datos de la feromona (Ver Figura \ref{mem_org_tag}) indica si la feromona fue difundida de forma parásita o no.

\subsection{Systema de Feromonas Artificiales Para Navegación autónoma de Robots \cite{Her07}}

Los tags de RFID son utilizados para almacenar la información, estos \textit{tags} pueden ser leídos y escritos muchas veces de forma individual y simultánea. Cada agente posee un \textit{reader}, con lo que pueden construir el campo de potencial de la feromona. El proceso de difusión del campo de potencial se refresca cada vez que se establece una comunicación entre el robot y los tags.

\subsubsection{Modelo de Densidad de la feromona}
Los sistemas de feromonas artificiales representan información sobre el sistema. Diferentes densidades de feromonas transportan diferentes tipos de información. El modelo de difusión y evaporación sugerido por Sugawara \cite{SKKT04} es:\\
$\frac{\delta u}{\delta t} = D(\frac{\delta u^2}{\delta x^2} + \frac{\delta u^2}{\delta y^2}) - Ku$

donde: $u(t,x,y)$ es la densidad de feromona, $t$ el tiempo y $(x,y)$ la coordenada. $D$ y $K$ denotan los coeficientes de difusión y evaporación respectivamente. Al convertir esta fórmula a sistemas discretos $\Delta t, \Delta x, \Delta y$ corresponde a $t, x, y$. $ut_k, x_i, y_j$ corresponde a $t_k = k\Delta t$, $x_i = i\Delta x$ y $y_j = j\Delta y$.la ecuación para el punto $U_{ij}(k)$ es: \\
$U_{i,j}(k+1) = (1 - \Delta tK - 2\alpha D - 2\beta D) U_{i,j}(k)$\\
$               + \alpha D(U_{i-1,j}(k) + U_{i+1,j}(k))$\\
$               + \beta D(U_{i,j-1}(k) + U_{i,j+1}(k))$

donde: $\alpha = \frac{\Delta t}{(\Delta x)^2}$, $\beta = \frac{\Delta t}{(\Delta y)^2}$. Además el sistema se vuelve inestable debida a las relaciones entre $\alpha$ y $\beta$. Es necesario que se cumpla:\\
$\frac{\Delta t}{(\Delta x)^2} \leq \frac{1}{4}, \frac{\Delta t}{(\Delta y)^2} \leq \frac{1}{4}$
haciendo:\\

$\zeta = \alpha D, \eta = \beta D, \xi = 1 - \Delta tK - 2(\alpha + \beta) D$

La ecuación para la difusión en sistemas discretos es:

$U_{i,j}(k+1) = \xi U_{i,j}(k) + \zeta (U_{i-1,j}(k) + U_{i+1,j}(k)) + \eta (U_{i,j-1}(k) + U_{i,j+1}(k))$

\subsubsection{Realización de la Feromona}
El proceso de renovación de la feronoma se presenta si se conoce la densidad del vecindario. El proceso de comunicación de un robot moviéndose con una feromona se muestra en la figura \ref{comm_reg_mov_rob}.

\begin{figure}[ht]
\begin{center} \includegraphics[scale=.5]{./images/tag_renewed}   \end{center}
\caption{Transición del rango de comunicación} \label{comm_reg_mov_rob} 
\end{figure}

Existen tres condiciones que gobiernan la comunicación entre los tags y el robot móvil: (1) Los tags son distribuidos de forma regular. (2) Los robots poseen información de los tags cercanos a éllos o dentro de un rango de comunicación. (3) La renovación es posible únicamente para los tags que se encuentran dentro del rango de comunicación y el robot que posee la información relacionada con la densidad del vecindario. Si se utiliza un número muy grande de tags se puede ignorar la condición (1) ya que se puede asumir que los tags están muy cerca unos de otros en un arreglo aleatorio; por lo que solo se considerarán las condiciones (2) y (3).

Asumiendo que el tag es leído dentro del rango de comunicación por cierto robot en el tiempo $t = k\Delta t$ y el valor medio es $U_r(k)$. Suponiendo que la dirección de movimiento del robot es igual estocásticamente, se puede asumir que: \\

$U_{i-1,j}(k) + U_{i+1,j}(k) = U_{i,j-1}(k) + U_{i,j+1}(k)$\\
$= U_r(k - 1) + U_r(k + 1)$

Con lo que la ecuación para la difusión en sistemas discretos queda:\\

$U_{i,j}(k+1) = (1 - \Delta tK - 2\alpha D - 2\beta D) U_{i,j}(k)$\\
$               + (\alpha + \beta) D(U_r(k - 1) + U_r(k + 1))$

Ciertos tags se comunican con el robot cada cierto intervalo de tiempo $T$. Por lo que:\\
$U_{i,j}(k+T) = \xi^TU_{i,j}(k) + (\zeta + \eta)\sum_{i=0}^{T-1}\xi^i(U_r(k - 1) + U_r(k + 1))$

La Figura \ref{comm_reg_mov_rob} muestra la transición del rango de comunicación cuando el robot mantiene una velocidad constante en un movimiento lineal. $S_0$ es el rango de comunicación actual $S_+$ $S_-$ son los rangos anteriores y posteriores respectivamente. Antes de que el robot realice el proceso de escritura, se mantienen los valores de $S_0$, $S_+$ y $S_-$. Las densidades promedio dentro de $S_+$ y $S_-$ son respectivamente $U_r^+$ y $U_r^-$. Estos valores de densidad son reemplazados por $U_r(k + 1) U_r(k - 1)$.

Como se dijo anteriormente, únicamente se renueva la información de los tags que pertenecen al vecindario y cuya información es conocida por el robot. Esto implica que el robot procesa la información de densidad de los tags que serán renovados basándose en la información de los pasos anterior y posterior al almacenado actualmente en el tag. Por lo tanto, solo los tags de la regíon $S_{0+}$ (Figura \ref{comm_reg_mov_rob}) serán renovados. Si el radio de comunicación es $r_{r0}$ y la velocidad del robot es $v_{r0}$, la región $S_{0+}$ puede ser determinada.


\subsubsection{Construcción del Potencial de Campo de la Feromona}

Como plataforma robótica se utilizó el \textit{e-puck} desarrollado por el Swiss Federal Institute of Technology in Lausanne (EPFL). En los experimentos, los robots se mueven cerca de los tags. Cuando detectan uno, se lee su número de identificación único (UID) y se detemina si el tag es nuevo o no. Si es nuevo, el robot lee información del tag y basándose en la información del vecindario realiza el proceso de renovación de la feromona. Las características del potencial de campo de la feromona dependen de los coeficientes de difusión y evaporación.

